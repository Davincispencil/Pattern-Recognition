{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISODATA 算法实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset length:150, width:4\n"
     ]
    }
   ],
   "source": [
    "#加载数据并显示\n",
    "iris = datasets.load_iris()\n",
    "[length, width] = iris.data.shape\n",
    "print('iris dataset length:%d, width:%d' % (length,width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Initial_Center类包含五种初始化方法\n",
    "class Initial_Center():\n",
    "    #初始化函数记录用于类别个数k\n",
    "    #Random_Center对应随机选取数据中心的方法 整个数据集作为输入参数\n",
    "    #Empircal_Center 对应随机选取数据中心的方法 以指定的数据中心作为输入参数\n",
    "    #Random_MeanCenter 对应随机将数据分为K类取这K类数据的均值向量作为初始数据中心的方法 整个数据集作为输入参数\n",
    "    #FarDistance_Center 选择批次距离尽可能远的点作为初始数据中心 整个数据集作为输入参数\n",
    "    #Dense_Center 对应密度法求初始数据中心 \n",
    "    #输入整个数据集， r表示计算密度的半径 Dt是用于选择高密度集的阈值\n",
    "    #经过对数据的计算分析， iris数据集r取0.4，Dt取6较合适\n",
    "    def __init__(self,k):\n",
    "        self.n_class = k\n",
    "        \n",
    "    def Random_Center(self,dataset):\n",
    "        [length, width] = dataset.shape\n",
    "        indices = random.sample(range(0, length),self.n_class)\n",
    "        self.initial_center  = dataset[indices]\n",
    "      \n",
    "    \n",
    "    def Empirical_Center(self,Centers):\n",
    "        self.initial_center = Centers\n",
    "    \n",
    "    def Random_MeanCenter(self,dataset):\n",
    "        [length, width] = dataset.shape\n",
    "        length = length - length % self.n_class\n",
    "        \n",
    "        indices = random.sample(range(0, length),length)\n",
    "        self.initial_center  = np.mean(dataset[indices].reshape((self.n_class,-1,width)), 1)\n",
    "        \n",
    "    \n",
    "    def FarDistance_Center(self,dataset):\n",
    "        [length, width] = dataset.shape\n",
    "        self.initial_center = np.zeros((self.n_class,width))\n",
    "        self.indices = random.sample(range(0, length),self.n_class)\n",
    "        self.indices[0] = np.random.randint(0,length)\n",
    "        self.initial_center[0] = dataset[self.indices[0]]\n",
    "        self.distance = np.sum(np.square(dataset - self.initial_center[0]),1)\n",
    "            \n",
    "        for i in range(self.n_class-1):\n",
    "            self.distance += np.sum(np.square(dataset - self.initial_center[i]),1)\n",
    "            indice = np.argmax(self.distance)\n",
    "            #print(np.max(self.distance))\n",
    "            #print(np.min(self.distance))\n",
    "            if indice in self.indices:\n",
    "                self.distance[indice] = 0\n",
    "                \n",
    "            self.indices[i+1] = np.argmax(self.distance)\n",
    "            \n",
    "        #print(sef.indices)   \n",
    "        self.initial_center = dataset[self.indices]\n",
    "       \n",
    "    \n",
    "    def Calcul_Dense(self,dataset,r):\n",
    "        [length,width] = dataset.shape\n",
    "        self.dense = np.zeros((length,))\n",
    "        \n",
    "        for i in range(length):\n",
    "            decision = np.zeros((length,))\n",
    "            temp_distance = np.sum(np.square(dataset - dataset[i]),1)\n",
    "            decision[temp_distance <= r*r] = 1\n",
    "            self.dense[i] = np.sum(decision)\n",
    "            #print(self.dense[i]-1)\n",
    "            \n",
    "            \n",
    "    def Dense_Center(self,dataset,r,Dt):\n",
    "        [length, width] = dataset.shape\n",
    "        self.initial_center = np.zeros((self.n_class,width))\n",
    "        self.Calcul_Dense(dataset,r)\n",
    "        dataset = dataset[self.dense > Dt]\n",
    "        temp_matrix = self.dense[self.dense > Dt]\n",
    "        #print(temp_matrix)\n",
    "        self.indices = random.sample(range(0, length),self.n_class)\n",
    "        self.indices[0] = np.argmax(temp_matrix)\n",
    "        \n",
    "        self.initial_center[0] = dataset[self.indices[0]]\n",
    "        self.distance = np.sum(np.square(dataset - self.initial_center[0]),1)\n",
    "            \n",
    "        for i in range(self.n_class-1):\n",
    "            self.distance += np.sum(np.square(dataset - self.initial_center[i]),1)\n",
    "            indice = np.argmax(self.distance)\n",
    "            #print(np.max(self.distance))\n",
    "            #print(np.min(self.distance))\n",
    "            if indice in self.indices:\n",
    "                self.distance[indice] = 0\n",
    "                \n",
    "            self.indices[i+1] = np.argmax(self.distance)\n",
    "            \n",
    "        #print(sef.indices)   \n",
    "        self.initial_center = dataset[self.indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISODATA():\n",
    "    #__init__函数初始化ISODATA类的重要参数\n",
    "        #centers -> Nc个初始聚类中心\n",
    "        #k -> 预期的聚类中心数目\n",
    "        #Theta_n -> 每一个聚类域中最少的样本数目，如果少于这个数目就不作为一个独立的聚类域\n",
    "        #Theta_s -> 聚类域中样本距离分布的标准差\n",
    "        #Theta_c -> 两聚类中心之间的最小距离，小于此距离，两个聚类合并\n",
    "        #L -> 一次迭代运算中可以合并的聚类还在那个心的最多对数\n",
    "        #r -> 分裂处理时，最大标准差分量取得比例\n",
    "        #self.MeanDistanceInClass -> 记录每一类中各数据到其类中心的平均距离\n",
    "        #self.MeansDistanceTotal -> 记录全部模式样本对其相应聚类中心的总平均距离\n",
    "        \n",
    "    #Labelling 函数按照最小距离准则给数据标签\n",
    "    #Clustering 函数按照均值计算新的聚类中心\n",
    "    #Operation_Division 分裂操作\n",
    "    #Operation_Merging 合并操作\n",
    "    #Interaction 函数作为人机交互接口，提供改变输入参数的功能\n",
    "\n",
    "    def __init__(self,centers,Nc,k,Theta_n, Theta_s, Theta_c, L):\n",
    "        self.centers = centers\n",
    "        self.Nc = Nc\n",
    "        self.n_class = k\n",
    "        self.Theta_n = Theta_n\n",
    "        self.Theta_s = Theta_s\n",
    "        self.Theta_c = Theta_c\n",
    "        self.L = L\n",
    "        self.r = 0.5\n",
    "        \n",
    "        self.length = int(0)\n",
    "        self.width = int(0)\n",
    "        \n",
    "        \n",
    "    def Labelling(self,dataset):\n",
    "        self.MeanDistanceInClass = np.zeros((self.Nc,))\n",
    "        self.MeanDistanceTotal = 0.0\n",
    "        self.num_per_class = np.zeros((self.Nc,))\n",
    "        \n",
    "        if self.centers.size == 0:\n",
    "            print('parameters wrong!!! centers matrix is empty now!')\n",
    "            \n",
    "        [length,width] = dataset.shape\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.labels = np.zeros((self.length,))\n",
    "        \n",
    "        for i in range(self.length):\n",
    "            self.labels[i] = np.argmin(np.sum(np.square(np.ones((self.Nc,1)) * dataset[i,:] - self.centers),1))\n",
    "        \n",
    "        for i in range(self.Nc):\n",
    "            self.num_per_class[i] = self.labels[self.labels == i].size\n",
    "  \n",
    "            \n",
    "    def Merge_Small_Class(self,dataset):\n",
    "        temp = self.Nc\n",
    "        for i in range(self.Nc):\n",
    "            indice = temp - i - 1\n",
    "            if self.num_per_class[indice] < self.Theta_n:\n",
    "                self.centers = np.delete(self.centers,indice,axis=0)\n",
    "                self.Nc -= 1\n",
    "                print('Merge Small Class!!!')\n",
    "        self.Labelling(dataset)\n",
    "        \n",
    "        \n",
    "    def Clustering(self,dataset):\n",
    "        centers = np.zeros_like(self.centers)\n",
    "        for i in range(self.Nc):\n",
    "            cluster_class = dataset[self.labels == i]\n",
    "            self.centers[i] = np.mean(cluster_class,0)\n",
    "            \n",
    "            [length,width] = cluster_class.shape\n",
    "            Temp =  np.sum(np.sqrt(np.sum(np.square(cluster_class - self.centers[i]),1)))\n",
    "            self.MeanDistanceInClass[i] = Temp / length\n",
    "            self.MeanDistanceTotal += Temp\n",
    "            \n",
    "        \n",
    "        self.MeanDistanceTotal = self.MeanDistanceTotal / self.length\n",
    "        \n",
    "\n",
    "    def Operation_Division(self):\n",
    "        print('Enter Operation Division Function')\n",
    "        self.StandardError = np.zeros((self.Nc,self.width))\n",
    "        for i in range(self.Nc):\n",
    "            cluster_class = dataset[self.labels == i]\n",
    "            self.StandardError[i,:] = np.sqrt(np.mean(np.square(cluster_class - self.centers[i]),0))\n",
    "        \n",
    "        MaxStandardErrorVector = np.max(self.StandardError,1)\n",
    "        \n",
    "        flag = 1\n",
    "        for i in range(self.Nc):\n",
    "            if (MaxStandardErrorVector[i] > self.Theta_s):\n",
    "                if (self.Nc <= self.n_class/2) or (self.MeanDistanceInClass[i] > self.MeanDistanceTotal and self.num_per_class[i] > 2*(self.Theta_n + 1)):\n",
    "                    flag = 0\n",
    "                    indice = np.argmax(self.StandardError[i,:])\n",
    "                    new_center1 = self.centers[i,:]\n",
    "                    new_center2 = self.centers[i,:]\n",
    "                    new_center1[indice] += self.r *  MaxStandardErrorVector[i]\n",
    "                    new_center2[indice] -= self.r *  MaxStandardErrorVector[i]\n",
    "                    self.centers = np.delete(self.centers,i,axis=0)\n",
    "                    self.centers = np.append(self.centers,[new_center1],axis=0)\n",
    "                    self.centers = np.append(self.centers,[new_center2],axis=0)\n",
    "                    self.Nc += 1\n",
    "                    print('Nc = ',self.Nc)\n",
    "        return flag\n",
    "        \n",
    "    def Operation_Merging(self):\n",
    "        print('Enter Operation Merging Function')\n",
    "        Distance_Center2Center = np.ones((self.Nc,self.Nc)) * 1000000\n",
    "        for i in range(self.Nc):\n",
    "            for j in range(self.Nc):\n",
    "                if j > i :\n",
    "                    distance = np.sqrt(np.sum(np.square(self.centers[i]- self.centers[j])))\n",
    "                    Distance_Center2Center[i][j] = distance \n",
    "                    \n",
    "        temp = Distance_Center2Center[Distance_Center2Center < self.Theta_c]\n",
    "        temp = np.sort(temp)\n",
    "        if temp.size > 0:\n",
    "            indice = np.argwhere(Distance_Center2Center == temp[0])\n",
    "            indice1 = indice[0][0]\n",
    "            indice2 = indice[0][1]\n",
    "            \n",
    "            num =  self.num_per_class[indice1] + self.num_per_class[indice2]\n",
    "            total = self.centers[indice1,:] * self.num_per_class[indice1] + self.centers[indice2,:] * self.num_per_class[indice2]\n",
    "            new_center = total / num\n",
    "            self.centers = np.delete(self.centers,indice2,axis=0)\n",
    "            self.centers = np.delete(self.centers,indice1,axis=0)\n",
    "            self.centers = np.append(self.centers,[new_center],axis=0)\n",
    "                                                                                                                    \n",
    "            self.Nc -= 1\n",
    "            print('Nc = ',self.Nc)\n",
    "    \n",
    "    def Interaction(self):\n",
    "        print('current algo parameters:\\n')\n",
    "        print('self.Nc: ',self.Nc)\n",
    "        print('self.centers：\\n',self.centers)\n",
    "        print('n_class: ',self.n_class)\n",
    "        print('Theta_n: ',self.Theta_n)\n",
    "        print('Theta_s: ',self.Theta_s)\n",
    "        print('Theta_c：',self.Theta_c)\n",
    "        print('L: ',self.L)\n",
    "        \n",
    "        print('please input new parameters:\\n')\n",
    "        self.n_class = float(input('new k:'))\n",
    "        self.Theta_n = float(input('new Theta_n:'))\n",
    "        self.Theta_s = float(input('new Theta_s:'))\n",
    "        self.Theta_c = float(input('new Theta_c:'))\n",
    "        self.L = float(input('new L:'))\n",
    "        \n",
    "        \n",
    "    def Training(self,dataset,iteration):\n",
    "        for i in range(iteration):\n",
    "            print('iteration:',i)\n",
    "            FlagChange = 0\n",
    "            if i> 1 and  i%5 == 0:\n",
    "                FlagChange = int(input('Change Parameters?[1\\Yes|0|No]'))    \n",
    "                if FlagChange == 1:\n",
    "                    self.Interaction()\n",
    "            self.Labelling(dataset)\n",
    "            self.Merge_Small_Class(dataset)\n",
    "            self.Clustering(dataset)\n",
    "            if i == iteration -1 : \n",
    "                self.Theta_c = 0\n",
    "                self.Operation_Merging()\n",
    "                break\n",
    "            \n",
    "            if self.Nc <= self.n_class/2 or (self.Nc < 2*self.n_class and i%2 == 1):\n",
    "                flag = self.Operation_Division()\n",
    "                print('flag:',flag)\n",
    "                if flag == 0 :\n",
    "                    continue\n",
    "            if self.Nc >= 2*self.n_class or (i%2 == 0):\n",
    "                self.Operation_Merging()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_centers indices:  [29, 55, 42, 56, 45, 53]\n",
      "initial_centers: \n",
      " [[5.6 2.7 4.2 1.3]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [6.7 3.1 5.6 2.4]]\n"
     ]
    }
   ],
   "source": [
    "#定义取初始聚类中心的重要变量\n",
    "Nc = 6\n",
    "r = 0.4\n",
    "Dt = 3\n",
    "k = 3\n",
    "Theta_n = 10\n",
    "Theta_s = 0.6\n",
    "Theta_c = 3\n",
    "L = 2\n",
    "#导入数据集计算初始聚类中心\n",
    "#dataset = iris.data[0:100,:]\n",
    "#dataset = np.vstack((iris.data[0:50,:],iris.data[100:150,:]))\n",
    "dataset = iris.data[50:150,:]\n",
    "#dataset = iris.data\n",
    "[length,width] = dataset.shape\n",
    "#给出了五种不同的取初始聚类中心的方法\n",
    "center = Initial_Center(Nc)\n",
    "#center.Random_Center(iris.data)\n",
    "#center.FarDistance_Center(dataset)\n",
    "center.Dense_Center(dataset,r,Dt)\n",
    "print('initial_centers indices: ',center.indices)\n",
    "print('initial_centers: \\n',center.initial_center)\n",
    "#Centers = np.zeros((k,width))\n",
    "#center.Empirical_Center(Centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "Merge Small Class!!!\n",
      "Merge Small Class!!!\n",
      "Enter Operation Merging Function\n",
      "Nc =  3\n",
      "iteration: 1\n",
      "Enter Operation Division Function\n",
      "flag: 1\n",
      "iteration: 2\n",
      "Enter Operation Merging Function\n",
      "Nc =  2\n",
      "iteration: 3\n",
      "Enter Operation Merging Function\n"
     ]
    }
   ],
   "source": [
    "#创建isodata_test1 类并初始化\n",
    "centers = center.initial_center\n",
    "Iteration = 4\n",
    "isodata_test1 = ISODATA(centers,Nc,k,Theta_n, Theta_s,Theta_c, L)\n",
    "isodata_test1.Training(dataset,Iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.12272727 3.11363636 6.03181818 2.13181818]\n",
      " [6.01923077 2.80384615 4.58846154 1.5474359 ]]\n"
     ]
    }
   ],
   "source": [
    "print(isodata_test1.centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1.]\n",
      " [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      "  0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      "  1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(isodata_test1.labels.reshape((2,50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
