{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模式识别实验二：神经网络算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#导入库文件\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义神经网络类及其函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义sigmoid函数\n",
    "def sigmoid(data):\n",
    "    return 1.0 /(1.0 + np.exp(-data))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义sigmoid函数的导数\n",
    "def derive_sigmoid(data):\n",
    "    return sigmoid(data)*(1 - sigmoid(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPNN:\n",
    "    #定义初始化函数\n",
    "    #n_input,n_nodes,n_output分别为输入层、隐层、输出层节点个数\n",
    "    def init_function(self,n_input,n_nodes,n_output):\n",
    "        self.n_output = n_output\n",
    "        self.value1 = np.random.random((n_nodes,n_input+1))*0.1\n",
    "        self.value2 = np.random.random((self.n_output,n_nodes+1))*0.1\n",
    "        self.hiddenlayer_input = np.zeros((n_nodes,1))\n",
    "        self.outputlayer_input = np.zeros((n_output,1))\n",
    "        self.predict = np.zeros((self.n_output,1))\n",
    "        self.error = self.predict\n",
    "    \n",
    "    def forward_function(self,data):\n",
    "        self.hiddenlayer_input = self.value1 @ data\n",
    "        hiddenlayer_output = np.vstack((sigmoid(self.hiddenlayer_input),[1]))\n",
    "        \n",
    "        self.outputlayer_input = self.value2 @ hiddenlayer_output\n",
    "        self.predict = sigmoid(self.outputlayer_input)\n",
    "        \n",
    "    def backward_function(self,data,label,alpha):\n",
    "        self.error = self.predict - label\n",
    "        \n",
    "        sigma2 = self.error * derive_sigmoid(self.outputlayer_input)\n",
    "        sigma1 = np.transpose(self.value2[:,:-1]) @ sigma2 * derive_sigmoid(self.hiddenlayer_input)\n",
    "    \n",
    "        delta2 = sigma2 @ np.vstack((sigmoid(self.hiddenlayer_input),[1])).T\n",
    "        \n",
    "        delta1 = sigma1 @ data.T\n",
    "        \n",
    "        self.value2 = self.value2 - delta2 * alpha \n",
    "        self.value1 = self.value1 - delta1 * alpha \n",
    "        \n",
    "    def train_function(self,dataset,labels,alpha,iteration):\n",
    "        [length,width] = dataset.shape\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            indice = np.random.randint(length)\n",
    "            data = dataset[indice,:].reshape((width,1))\n",
    "            label = labels[indice,:].reshape((self.n_output,1))\n",
    "            self.forward_function(data)\n",
    "            self.backward_function(data,label,alpha)\n",
    "        print('training process finished')\n",
    "        \n",
    "    def predict_function(self,dataset):\n",
    "        [length,width] = dataset.shape\n",
    "        predict = np.zeros((length,self.n_output))\n",
    "        \n",
    "        for i in range(length):\n",
    "            data = dataset[i,:].reshape((width,1))\n",
    "            self.forward_function(data)\n",
    "            indice = np.argmax(self.predict)\n",
    "            predict[i,indice] = 1\n",
    "        return predict\n",
    "    \n",
    "    def loss_function(self,predict,labels):\n",
    "        errors = predict - labels\n",
    "        errors = np.sum(abs(errors),1)/2 \n",
    "        error_rate = np.mean(errors)\n",
    "        print('error_rate: ',error_rate)\n",
    "        return errors\n",
    "        \n",
    "    def pretrait_function(self,dataset,pre_labels):\n",
    "        [length,width] = dataset.shape\n",
    "        dataset = np.hstack((dataset,np.ones((length,1))))\n",
    "        \n",
    "        labels = np.zeros((length,self.n_output))\n",
    "        for i in range(length):\n",
    "            indice = int(pre_labels[i])\n",
    "            labels[i,indice] = 1\n",
    "        return dataset,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP算法 异或问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  (200, 2)\n",
      "labels size:  (200, 1)\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[0,0],[0,1],[1,1],[1,0]]).reshape(4,2)\n",
    "label = np.array([[0],[1],[0],[1]])\n",
    "dataset1 = (np.random.random((50,2)) - 0.5) * 0.2 + data[0,:]\n",
    "dataset2 = (np.random.random((50,2)) - 0.5) * 0.2 + data[1,:]\n",
    "dataset3 = (np.random.random((50,2)) - 0.5) * 0.2 + data[2,:]\n",
    "dataset4 = (np.random.random((50,2)) - 0.5) * 0.2 + data[3,:]\n",
    "pre_dataset = np.vstack((dataset1,dataset2,dataset3,dataset4))\n",
    "\n",
    "pre_labels = np.zeros((200,1))\n",
    "pre_labels[50:100] = 1\n",
    "pre_labels[150:200] = 1\n",
    "\n",
    "print('dataset size: ', pre_dataset.shape)\n",
    "print('labels size: ',pre_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training process finished\n",
      "error_rate:  0.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "bpnn = BPNN()\n",
    "bpnn.init_function(2,5,2)\n",
    "[dataset, labels] = bpnn.pretrait_function(pre_dataset,pre_labels)\n",
    "X_train,X_test,y_train,y_test = train_test_split(dataset, labels, test_size = 0.2, random_state = 0)\n",
    "bpnn.train_function(X_train,y_train,alpha=1,iteration=5000)\n",
    "predict = bpnn.predict_function(X_test)\n",
    "errors = bpnn.loss_function(predict,y_test)\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP算法 Iris数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "#加载数据并显示\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "#data对应了样本的4个特征，150行4列\n",
    "print(iris.data.shape) \n",
    "\n",
    "#target对应样本的标签，150行1列\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training process finished\n",
      "error_rate:  0.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "iris_bpnn = BPNN()\n",
    "iris_bpnn.init_function(4,10,3)\n",
    "[dataset, labels] = iris_bpnn.pretrait_function(iris.data,iris.target)\n",
    "X_train,X_test,y_train,y_test = train_test_split(dataset, labels, test_size = 0.2, random_state = 0)\n",
    "iris_bpnn.train_function(X_train,y_train,alpha=0.5,iteration=5000)\n",
    "predict = iris_bpnn.predict_function(X_test)\n",
    "errors = iris_bpnn.loss_function(predict,y_test)\n",
    "print(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
